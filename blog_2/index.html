<!DOCTYPE html>
<html>
<head>

  <title>Blog Post 2</title>
  <meta charset="utf-8">
  <meta name="description" content="">
  <meta name="author" content=""> <!-- Your name here -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="http://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css">
  <!--# CSS #}-->
  <link rel="stylesheet" href="style.css"> <!-- Add your CSS to this file -->

  <!--# JAVASCRIPT #}-->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js"></script> <!-- JQUERY -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.16/d3.min.js"></script> <!-- D3.js -->
  <script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
</head>

<body>

<div class="row">
        <div class="col-md-2"></div>
        <div class="col-md-8">
            <div class="page-header center">
                <h1>Blog Post 2: <small>&laquo;Reddit Analysis&raquo;</small></h1>
            </div>

      <h2>Members</h2>
      The members of this group are mjzhu, bp12, eh49, and amai.

      <h2>What We Did This Week</h2>

      <h3>Solr</h3>
      We are still in the process of uploading all the files to Solr. Fortunately, I wrote a script that automates most of the process so we can upload stuff 24/7; unfortunately, Solr is slow and needs to read through every single line of input as well as process everything so it can index it.
      <br>
      The good news is, we have successfuly had our other servers use an HTTP request to query our Solr instance. This shows that all we need to do for our Spark cluster is to launch HTTP requests to get the data. We also saw that the main bottleneck of getting data out of Solr is the network speed; while Solr itself is blazingly fast, there is so much data for simple queries (i.e. all posts that contain the word "hello") that it takes a while (30 seconds) to transfer over HTTP. However, this is acceptable in light of the circumstances, as we are dealing with massive amounts of data and running Spark jobs on the fly, two things where if we used the traditional approaches as taught in class would probably take hours.

      <h3>Spark</h3>
      On the Spark side of things, we've actually set up an SBT project for Scala and wrote a simple Spark job that reads in a local text file and does some word counting. We are currently working on integrating the Spark job with the Solr server by modifying the word counting to count the response from the Solr server. We are using scalaj-http to make http requests to the Solr server in order to query the dataset. The response from the Solr server is in xml, but thankfully Scala has native xml parsing support so parsing the response should be easy. After we finish integrating the Spark job with Solr, we will use the already set up spark-jobserver to allow the Flask web server to make requests to start Spark jobs.

      <h3>Flask</h3>
      We had a bit of trouble with Flask because it is not a production-ready server, so many things being served on it is extremely slow. The solution is to run Flask with gunicorn on an nginx server, which took a while to set up since this is the first time most of us have even touched Flask. There was a very annoying bug where we tried to get gunicorn to actually run our flask app, but it turned out that the error was, for some reason, caused by naming our object "app" instead of "application". Changing that made the entire thing work, and now we have a dummy visualization set up <a href="http://ec2-54-175-87-193.compute-1.amazonaws.com/">here</a>. This is proof that our webapp is up and running, and we just have to fill in the server code to make the appropriate requests and serve the correct pages.

      <h3>Algorithms</h3>
      We have begun to look at prototypes for many of the algorithms that we will want to implement. In particular, we are currently using IntelliJ IDEA CE to build a prototype of the Flesch-Kinkaid grade level test. One trouble that we are running in to is how to accurately count the number of syllables in each reddit comment, and we are looking into using a built-in syllable dictionary through Java to count the number of syllables. Here is an example of the code we are currently working on: <img src="algorithms.jpg" alt="Algorithms" style="width:297px;height:213px;">
        <div class="col-md-2"></div>
    </div>  

</body>

</html>
